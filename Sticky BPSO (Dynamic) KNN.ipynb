{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Import backend modules\n",
    "import pyswarms.backend as P\n",
    "from pyswarms.backend.topology import Star\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_per_particle(m):\n",
    "    classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "    \"\"\"Computes for the fitness function per particle\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    m : numpy.ndarray\n",
    "        Binary mask that can be obtained from BinaryPSO, will\n",
    "        be used to mask features.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Computed finess function\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the subset of the features from the binary mask\n",
    "    if np.count_nonzero(m) == 0:\n",
    "        X_subset = X_train\n",
    "        X_subset_test= X_test\n",
    "    else:\n",
    "        X_subset = X_train[:,m==1]\n",
    "        X_subset_test= X_test[:,m==1]\n",
    "        \n",
    "    \n",
    "    # Perform classification and compute the fitness function\n",
    "    classifier.fit(X_subset, y_train)\n",
    "    j = (classifier.predict(X_subset_test) != y_test).mean() + np.count_nonzero(m)\n",
    "#     j=np.count_nonzero(m)\n",
    "\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    \"\"\"Higher-level method to do classification in the\n",
    "    whole swarm.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    x: numpy.ndarray of shape (n_particles, dimensions)\n",
    "        The swarm that will perform the search\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray of shape (n_particles, )\n",
    "        The computed loss for each particle\n",
    "    \"\"\"\n",
    "    n_particles = x.shape[0]\n",
    "    j = [f_per_particle(x[i]) for i in range(n_particles)]\n",
    "    \n",
    "    return np.array(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_position(swarm):\n",
    "        \"\"\"Update the position matrix of the swarm\n",
    "        This computes the next position in a binary swarm. It compares the\n",
    "        sigmoid output of the velocity-matrix and compares it with a randomly\n",
    "        generated matrix.\n",
    "        Parameters\n",
    "        ----------\n",
    "        swarm: pyswarms.backend.swarms.Swarm\n",
    "            a Swarm class\n",
    "        \"\"\"\n",
    "        \n",
    "        temp=np.random.random_sample(size=(swarm.n_particles,swarm.dimensions)) < swarm.velocity\n",
    "        postion=np.empty((my_swarm.n_particles, my_swarm.dimensions))\n",
    "        postion1=swarm.position\n",
    "\n",
    "        for j in range(swarm.n_particles):\n",
    "            for i in range(len(temp[0])):\n",
    "                if (temp[j][i] == True ):                  \n",
    "                    postion[j][i]=1-postion1[j][i]\n",
    "                else:\n",
    "                    postion[j][i]=postion1[j][i]\n",
    "            \n",
    "                \n",
    "        \n",
    "        return postion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_velocity(my_swarm, stickness,Is ,bounds=None):\n",
    "    \"\"\"Update the velocity matrix\n",
    "    This method updates the velocity matrix using the best and current\n",
    "    positions of the swarm. The velocity matrix is computed using the\n",
    "    cognitive and social terms of the swarm. The velocity is handled\n",
    "    by a :code:`VelocityHandler`.\n",
    "    A sample usage can be seen with the following:\n",
    "    .. code-block :: python\n",
    "        import pyswarms.backend as P\n",
    "        from pyswarms.swarms.backend import Swarm, VelocityHandler\n",
    "        my_swarm = P.create_swarm(n_particles, dimensions)\n",
    "        my_vh = VelocityHandler(strategy=\"invert\")\n",
    "        for i in range(iters):\n",
    "            # Inside the for-loop\n",
    "            my_swarm.velocity = compute_velocity(my_swarm, clamp, my_vh, bounds)\n",
    "    Parameters\n",
    "    ----------\n",
    "    swarm : pyswarms.backend.swarms.Swarm\n",
    "        a Swarm instance\n",
    "    clamp : tuple of floats, optional\n",
    "        a tuple of size 2 where the first entry is the minimum velocity\n",
    "        and the second entry is the maximum velocity. It\n",
    "        sets the limits for velocity clamping.\n",
    "    vh : pyswarms.backend.handlers.VelocityHandler\n",
    "        a VelocityHandler object with a specified handling strategy.\n",
    "        For further information see :mod:`pyswarms.backend.handlers`.\n",
    "    bounds : tuple of numpy.ndarray or list, optional\n",
    "        a tuple of size 2 where the first entry is the minimum bound while\n",
    "        the second entry is the maximum bound. Each array must be of shape\n",
    "        :code:`(dimensions,)`.\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Updated velocity matrix\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Prepare parameters\n",
    "        swarm_size = my_swarm.position.shape\n",
    "        alpha = my_swarm.options[\"c1\"]\n",
    "        gb=my_swarm.best_pos\n",
    "        Pb= my_swarm.pbest_pos\n",
    "        updated_velocity= np.empty((my_swarm.n_particles, my_swarm.dimensions))\n",
    "\n",
    "        for p in range(my_swarm.n_particles):\n",
    "            p_postion=my_swarm.position[p]\n",
    "            pb=Pb[p]\n",
    "\n",
    "            for i in range(len(p_postion)):                \n",
    "                if (p_postion[i] == pb[i] and   pb[i] == gb[i]):\n",
    "                    \n",
    "                    updated_velocity[p][i]=Is*(1-stickness[p][i])\n",
    "                elif(p_postion[i] == pb[i] and pb[i] != gb[i]):\n",
    "                    \n",
    "                    updated_velocity[p][i]=Is*(1-stickness[p][i] - (1/(alpha+1))) +(1/(alpha+1))\n",
    "                elif(p_postion[i] != pb[i] and p_postion[i]== gb[i]):\n",
    "                    \n",
    "                    updated_velocity[p][i]=Is*(1-stickness[p][i] - (alpha/(alpha+1))) +(alpha/(alpha+1))\n",
    "                elif(p_postion[i] != pb[i] and pb[i]== gb[i]):\n",
    "                    \n",
    "                    updated_velocity[p][i]= 1-Is*stickness[p][i]\n",
    "        \n",
    "\n",
    "    except AttributeError:\n",
    "        rep.logger.exception(\n",
    "            \"Please pass a Swarm class. You passed {}\".format(type(swarm))\n",
    "        )\n",
    "        raise\n",
    "    except KeyError:\n",
    "        rep.logger.exception(\"Missing keyword in swarm.options\")\n",
    "        raise\n",
    "    else:\n",
    "\n",
    "        return updated_velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stickness(stickness, old_position, ustkS, notchanged):\n",
    "    \n",
    "    new_stickness=np.empty((my_swarm.n_particles, my_swarm.dimensions))\n",
    "    new_position=my_swarm.position\n",
    "    \n",
    "    for j in range(my_swarm.n_particles):\n",
    "\n",
    "        \n",
    "        for i in range(len(stickness[j])):\n",
    "            if(new_position[j][i] == old_position[j][i]):\n",
    "                notchanged[j][i]+=1\n",
    "                if(notchanged[j][i] < ustkS):\n",
    "                    val=stickness[j][i] - (1/ustkS)\n",
    "                    if(val > 0):\n",
    "                        new_stickness[j][i]=val\n",
    "                    else:\n",
    "                        new_stickness[j][i]=0\n",
    "                else:\n",
    "                    new_stickness[j][i]=0   \n",
    "            else:\n",
    "                notchanged[j][i]=0\n",
    "                new_stickness[j][i]=1\n",
    "\n",
    "    return new_stickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_swarm():\n",
    "   \n",
    "\n",
    "    stickness=np.random.random_sample(size=(my_swarm.n_particles,my_swarm.dimensions))\n",
    "    notchanged=np.zeros((my_swarm.n_particles,my_swarm.dimensions))\n",
    "\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        my_swarm.current_cost = f(my_swarm.position) # Compute current cost\n",
    "        my_swarm.pbest_cost = f(my_swarm.pbest_pos)  # Compute personal best pos\n",
    "        my_swarm.pbest_pos, my_swarm.pbest_cost = P.compute_pbest(my_swarm) # Update and store\n",
    "\n",
    "\n",
    "\n",
    "        Is=Isu-(i/iterations) *(Isu-Isl)\n",
    "        ustkS = ustkSL + (i/iterations) *(ustkSU- ustkSL)\n",
    "\n",
    "        # Part 2: Update global best\n",
    "        # Note that gbest computation is dependent on your topology\n",
    "        if np.min(my_swarm.pbest_cost) < my_swarm.best_cost:\n",
    "            my_swarm.best_pos, my_swarm.best_cost = my_topology.compute_gbest(my_swarm)\n",
    "        if i%20==0:\n",
    "                print('Iteration: {} | my_swarm.best_cost: {:.4f}'.format(i+1, my_swarm.best_cost))\n",
    "\n",
    "        my_swarm.velocity = compute_velocity(my_swarm, stickness, Is)\n",
    "        old_position= my_swarm.position\n",
    "        my_swarm.position = _compute_position(my_swarm)\n",
    "        stickness= compute_stickness(stickness,old_position, ustkS, notchanged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_folder=\"D:\\\\SDP\\\\Dataset Dr.Sultan\\\\selected DS\"\n",
    "files = [os.path.join(root_folder, x) for x in os.listdir(root_folder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=['merged selected DS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['merged selected DS']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 | my_swarm.best_cost: 7.2043\n",
      "Iteration: 21 | my_swarm.best_cost: 0.2063\n",
      "Iteration: 41 | my_swarm.best_cost: 0.2063\n",
      "Iteration: 61 | my_swarm.best_cost: 0.2063\n",
      "Iteration: 81 | my_swarm.best_cost: 0.2063\n",
      "subset performance= 0.7936746987951807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\afnan\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "my_topology = Star() # The Topology Class\n",
    "my_options = {'c1': 0.6} # arbitrarily set\n",
    "n_particles= 20\n",
    "\n",
    "\n",
    "for file in files:\n",
    "#     ds=file.split(\"\\\\\")[4][0:-4]\n",
    "\n",
    "#     print(\"{} dataset...\".format(ds))\n",
    "    \n",
    "    ds=file\n",
    "    fr = open(\"Test/KNN/{}.txt\".format(ds), \"a\")\n",
    "    fr.write('parameters: '+str(my_options)+\"\\n\")\n",
    "    \n",
    "    # read the dataset and prepare it X for features and y for lables:\n",
    "    \n",
    "    df=pd.read_csv(file)\n",
    "    if( 'version' in df.columns):\n",
    "        X=np.array(df.drop(['bug','name.1','name', 'version'], axis=1))\n",
    "    else:\n",
    "        X=np.array(df.drop('bug', axis=1))\n",
    "    y=np.array(df.bug)\n",
    "    \n",
    "    # split dataset for training and testing DS\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    \n",
    "    # create swarm based on num of features and num of particles and the options \n",
    "    my_swarm = P.create_swarm(n_particles=n_particles,\n",
    "                              dimensions=X.shape[1], options=my_options, discrete=True, binary=True) # The Swarm Class\n",
    "    \n",
    "    # set swarm parameters \n",
    "    \n",
    "    iterations=100\n",
    "    ustkSL= 1*(iterations/100)\n",
    "    ustkSU= 8*(iterations/100)\n",
    "    Isu=0\n",
    "    Isl=10/my_swarm.dimensions\n",
    "    \n",
    "    # run swarm \n",
    "    run_swarm()\n",
    "    \n",
    "    # if the best pos no features select all features \n",
    "    if( np.count_nonzero( my_swarm.best_pos) == 0):\n",
    "        my_swarm.best_pos= np.ones(my_swarm.dimensions)\n",
    "    \n",
    "    # train the classfier on the selected features \n",
    "    classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "    X_selected_features = X_train[:,my_swarm.best_pos==1]\n",
    "    X_selected_features_test= X_test[:,my_swarm.best_pos==1]\n",
    "    classifier.fit(X_selected_features, y_train)\n",
    "    \n",
    "    # test it and evaluate \n",
    "    y_pred= classifier.predict(X_selected_features_test)    \n",
    "    report=classification_report(y_test,y_pred)\n",
    "    subset_performance = (y_pred== y_test).mean()\n",
    "    \n",
    "    # store the result \n",
    "    print(\"subset performance= {}\".format(subset_performance))\n",
    "    fr.write('number of particle {}:\\n'.format(n_particles))\n",
    "    fr.write(\"best pos cost= \"+str(my_swarm.best_cost)+\"\\nNumber of selected features:\"+str(len([i for i in my_swarm.best_pos if i==1]))+\"\\nSelected features:\"+str(my_swarm.best_pos))\n",
    "    fr.write(\"\\nclassification_report:\"+str(report)+\"\\n\")\n",
    "    fr.write(\"subset performance = {}\".format(subset_performance))\n",
    "    fr.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6034"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "5       0\n",
       "6       0\n",
       "7       0\n",
       "8       0\n",
       "9       1\n",
       "10      0\n",
       "11      1\n",
       "12      0\n",
       "13      0\n",
       "14      1\n",
       "15      0\n",
       "16      0\n",
       "17      0\n",
       "18      0\n",
       "19      0\n",
       "20      0\n",
       "21      0\n",
       "22      0\n",
       "23      0\n",
       "24      0\n",
       "25      0\n",
       "26      0\n",
       "27      0\n",
       "28      1\n",
       "29      0\n",
       "       ..\n",
       "6004    0\n",
       "6005    0\n",
       "6006    2\n",
       "6007    0\n",
       "6008    0\n",
       "6009    0\n",
       "6010    0\n",
       "6011    0\n",
       "6012    0\n",
       "6013    0\n",
       "6014    0\n",
       "6015    0\n",
       "6016    0\n",
       "6017    0\n",
       "6018    0\n",
       "6019    0\n",
       "6020    0\n",
       "6021    0\n",
       "6022    2\n",
       "6023    0\n",
       "6024    0\n",
       "6025    0\n",
       "6026    0\n",
       "6027    0\n",
       "6028    1\n",
       "6029    0\n",
       "6030    0\n",
       "6031    0\n",
       "6032    0\n",
       "6033    1\n",
       "Name: bug, Length: 6034, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.bug"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
