{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Import backend modules\n",
    "import pyswarms.backend as P\n",
    "from pyswarms.backend.topology import Star\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import arff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prepration(file):\n",
    "    data = arff.loadarff(file)\n",
    "    X=[]\n",
    "    y=[]\n",
    "    for i in data[0]:\n",
    "\n",
    "        X.append(list(i)[0:len(i)-2])\n",
    "        if(i[len(i)-1] == b'Y'):\n",
    "            y.append(1)\n",
    "        else:\n",
    "            y.append(0)\n",
    "        \n",
    "    X=np.array(X)\n",
    "    y=np.array(y)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_per_particle(m):\n",
    "    classifier = GaussianNB()\n",
    "    \"\"\"Computes for the fitness function per particle\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    m : numpy.ndarray\n",
    "        Binary mask that can be obtained from BinaryPSO, will\n",
    "        be used to mask features.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Computed finess function\n",
    "    \"\"\"\n",
    "    count_non_zero=np.count_nonzero(m)\n",
    "    # Get the subset of the features from the binary mask\n",
    "    if np.count_nonzero(m) == 0:\n",
    "        X_subset = X_train\n",
    "        X_subset_test= X_test\n",
    "        count_non_zero=len(m)\n",
    "    else:\n",
    "        \n",
    "        X_subset = X_train[:,m==1]\n",
    "        X_subset_test= X_test[:,m==1]\n",
    "        \n",
    "    \n",
    "    # Perform classification and compute the fitness function\n",
    "    classifier.fit(X_subset, y_train)\n",
    "    error_rate=(classifier.predict(X_subset_test) != y_test).mean()\n",
    "\n",
    "    j =  error_rate+ count_non_zero\n",
    "#     j=np.count_nonzero(m)\n",
    "\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    \"\"\"Higher-level method to do classification in the\n",
    "    whole swarm.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    x: numpy.ndarray of shape (n_particles, dimensions)\n",
    "        The swarm that will perform the search\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray of shape (n_particles, )\n",
    "        The computed loss for each particle\n",
    "    \"\"\"\n",
    "    n_particles = x.shape[0]\n",
    "    j = [f_per_particle(x[i]) for i in range(n_particles)]\n",
    "    \n",
    "    return np.array(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_position(swarm):\n",
    "        \"\"\"Update the position matrix of the swarm\n",
    "        This computes the next position in a binary swarm. It compares the\n",
    "        sigmoid output of the velocity-matrix and compares it with a randomly\n",
    "        generated matrix.\n",
    "        Parameters\n",
    "        ----------\n",
    "        swarm: pyswarms.backend.swarms.Swarm\n",
    "            a Swarm class\n",
    "        \"\"\"\n",
    "        \n",
    "        temp=np.random.random_sample(size=(swarm.n_particles,swarm.dimensions)) < swarm.velocity\n",
    "        postion=np.empty((my_swarm.n_particles, my_swarm.dimensions))\n",
    "        postion1=swarm.position\n",
    "\n",
    "        for j in range(swarm.n_particles):\n",
    "            for i in range(len(temp[0])):\n",
    "                if (temp[j][i] == True ):                  \n",
    "                    postion[j][i]=1-postion1[j][i]\n",
    "                else:\n",
    "                    postion[j][i]=postion1[j][i]\n",
    "            \n",
    "                \n",
    "        \n",
    "        return postion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_velocity(my_swarm, stickness,Is ,bounds=None):\n",
    "    \"\"\"Update the velocity matrix\n",
    "    This method updates the velocity matrix using the best and current\n",
    "    positions of the swarm. The velocity matrix is computed using the\n",
    "    cognitive and social terms of the swarm. The velocity is handled\n",
    "    by a :code:`VelocityHandler`.\n",
    "    A sample usage can be seen with the following:\n",
    "    .. code-block :: python\n",
    "        import pyswarms.backend as P\n",
    "        from pyswarms.swarms.backend import Swarm, VelocityHandler\n",
    "        my_swarm = P.create_swarm(n_particles, dimensions)\n",
    "        my_vh = VelocityHandler(strategy=\"invert\")\n",
    "        for i in range(iters):\n",
    "            # Inside the for-loop\n",
    "            my_swarm.velocity = compute_velocity(my_swarm, clamp, my_vh, bounds)\n",
    "    Parameters\n",
    "    ----------\n",
    "    swarm : pyswarms.backend.swarms.Swarm\n",
    "        a Swarm instance\n",
    "    clamp : tuple of floats, optional\n",
    "        a tuple of size 2 where the first entry is the minimum velocity\n",
    "        and the second entry is the maximum velocity. It\n",
    "        sets the limits for velocity clamping.\n",
    "    vh : pyswarms.backend.handlers.VelocityHandler\n",
    "        a VelocityHandler object with a specified handling strategy.\n",
    "        For further information see :mod:`pyswarms.backend.handlers`.\n",
    "    bounds : tuple of numpy.ndarray or list, optional\n",
    "        a tuple of size 2 where the first entry is the minimum bound while\n",
    "        the second entry is the maximum bound. Each array must be of shape\n",
    "        :code:`(dimensions,)`.\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Updated velocity matrix\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Prepare parameters\n",
    "        swarm_size = my_swarm.position.shape\n",
    "        alpha = my_swarm.options[\"c1\"]\n",
    "        gb=my_swarm.best_pos\n",
    "        Pb= my_swarm.pbest_pos\n",
    "        updated_velocity= np.empty((my_swarm.n_particles, my_swarm.dimensions))\n",
    "\n",
    "        for p in range(my_swarm.n_particles):\n",
    "            p_postion=my_swarm.position[p]\n",
    "            pb=Pb[p]\n",
    "\n",
    "            for i in range(len(p_postion)):                \n",
    "                if (p_postion[i] == pb[i] and   pb[i] == gb[i]):\n",
    "                    \n",
    "                    updated_velocity[p][i]=Is*(1-stickness[p][i])\n",
    "                elif(p_postion[i] == pb[i] and pb[i] != gb[i]):\n",
    "                    \n",
    "                    updated_velocity[p][i]=Is*(1-stickness[p][i] - (1/(alpha+1))) +(1/(alpha+1))\n",
    "                elif(p_postion[i] != pb[i] and p_postion[i]== gb[i]):\n",
    "                    \n",
    "                    updated_velocity[p][i]=Is*(1-stickness[p][i] - (alpha/(alpha+1))) +(alpha/(alpha+1))\n",
    "                elif(p_postion[i] != pb[i] and pb[i]== gb[i]):\n",
    "                    \n",
    "                    updated_velocity[p][i]= 1-Is*stickness[p][i]\n",
    "        \n",
    "\n",
    "    except AttributeError:\n",
    "        rep.logger.exception(\n",
    "            \"Please pass a Swarm class. You passed {}\".format(type(swarm))\n",
    "        )\n",
    "        raise\n",
    "    except KeyError:\n",
    "        rep.logger.exception(\"Missing keyword in swarm.options\")\n",
    "        raise\n",
    "    else:\n",
    "\n",
    "        return updated_velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stickness(stickness, old_position, ustkS, notchanged):\n",
    "    \n",
    "    new_stickness=np.empty((my_swarm.n_particles, my_swarm.dimensions))\n",
    "    new_position=my_swarm.position\n",
    "    \n",
    "    for j in range(my_swarm.n_particles):\n",
    "\n",
    "        \n",
    "        for i in range(len(stickness[j])):\n",
    "            if(new_position[j][i] == old_position[j][i]):\n",
    "                notchanged[j][i]+=1\n",
    "                if(notchanged[j][i] < ustkS):\n",
    "                    val=stickness[j][i] - (1/ustkS)\n",
    "                    if(val > 0):\n",
    "                        new_stickness[j][i]=val\n",
    "                    else:\n",
    "                        new_stickness[j][i]=0\n",
    "                else:\n",
    "                    new_stickness[j][i]=0   \n",
    "            else:\n",
    "                notchanged[j][i]=0\n",
    "                new_stickness[j][i]=1\n",
    "\n",
    "    return new_stickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_swarm():\n",
    "   \n",
    "\n",
    "    stickness=np.random.random_sample(size=(my_swarm.n_particles,my_swarm.dimensions))\n",
    "    notchanged=np.zeros((my_swarm.n_particles,my_swarm.dimensions))\n",
    "\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        my_swarm.current_cost = f(my_swarm.position) # Compute current cost\n",
    "        my_swarm.pbest_cost = f(my_swarm.pbest_pos)  # Compute personal best pos\n",
    "        my_swarm.pbest_pos, my_swarm.pbest_cost = P.compute_pbest(my_swarm) # Update and store\n",
    "\n",
    "\n",
    "\n",
    "        Is=Isu-(i/iterations) *(Isu-Isl)\n",
    "        ustkS = ustkSL + (i/iterations) *(ustkSU- ustkSL)\n",
    "\n",
    "        # Part 2: Update global best\n",
    "        # Note that gbest computation is dependent on your topology\n",
    "        if np.min(my_swarm.pbest_cost) < my_swarm.best_cost:\n",
    "            my_swarm.best_pos, my_swarm.best_cost = my_topology.compute_gbest(my_swarm)\n",
    "        if i%20==0:\n",
    "                print('Iteration: {} | my_swarm.best_cost: {:.4f}'.format(i+1, my_swarm.best_cost))\n",
    "\n",
    "        my_swarm.velocity = compute_velocity(my_swarm, stickness, Is)\n",
    "        old_position= my_swarm.position\n",
    "        my_swarm.position = _compute_position(my_swarm)\n",
    "        stickness= compute_stickness(stickness,old_position, ustkS, notchanged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_folder=\"D:\\\\SDP\\\\Afnan\"\n",
    "files = [os.path.join(root_folder, x) for x in os.listdir(root_folder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
