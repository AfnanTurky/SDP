{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection using BPSO for SDP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "installations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import pyswarms as ps\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The methods "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prepration(file):\n",
    "    df=pd.read_csv(file)\n",
    "    if( 'version' in file):\n",
    "        X=np.array(df.drop(['bug','name.1','name', 'version'], axis=1))\n",
    "    else:\n",
    "        X=np.array(df.drop('bug', axis=1))\n",
    "    y=np.array(df.bug)\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot data per feature (each class with different color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features(features,labels):\n",
    "    df = pd.DataFrame(features)\n",
    "    df['labels'] = pd.Series(labels)\n",
    "\n",
    "    sns.pairplot(df, hue='labels' , diag_kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fitness function for each particle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_per_particle(m):\n",
    "    if(clas=='NB'):\n",
    "        classifier = GaussianNB()\n",
    "    elif(clas=='SVM linear'):\n",
    "        classifier = svm.SVC(kernel='linear')\n",
    "    elif(clas=='KNN'):\n",
    "        classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "    elif(clas=='SVM RBF'):\n",
    "        classifier = svm.SVC(kernel='rbf')\n",
    "    \"\"\"Computes for the fitness function per particle\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    m : numpy.ndarray\n",
    "        Binary mask that can be obtained from BinaryPSO, will\n",
    "        be used to mask features.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Computed finess function\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the subset of the features from the binary mask\n",
    "    if np.count_nonzero(m) == 0:\n",
    "        X_subset = X_train\n",
    "        X_subset_test= X_test\n",
    "    else:\n",
    "        X_subset = X_train[:,m==1]\n",
    "        X_subset_test= X_test[:,m==1]\n",
    "        \n",
    "    \n",
    "    # Perform classification and compute the fitness function\n",
    "    classifier.fit(X_subset, y_train)\n",
    "    j = (classifier.predict(X_subset_test) != y_test).mean() \n",
    "#     j=np.count_nonzero(m)\n",
    "\n",
    "    return j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define fitness function for whole swarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    \"\"\"Higher-level method to do classification in the\n",
    "    whole swarm.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    x: numpy.ndarray of shape (n_particles, dimensions)\n",
    "        The swarm that will perform the search\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray of shape (n_particles, )\n",
    "        The computed loss for each particle\n",
    "    \"\"\"\n",
    "    n_particles = x.shape[0]\n",
    "    j = [f_per_particle(x[i]) for i in range(n_particles)]\n",
    "    \n",
    "    return np.array(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "select the features from the set of features X using BPSO on the specfied parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(nparticles):\n",
    "  \n",
    "    total_features = X.shape[1]\n",
    "    \n",
    "    dimensions = total_features\n",
    "    \n",
    "    optimizer = ps.discrete.BinaryPSO(n_particles=nparticles, dimensions=dimensions, options=options)\n",
    "    \n",
    "    # Perform optimization\n",
    "    cost, pos = optimizer.optimize(f, iters=iters)\n",
    "    \n",
    "    \n",
    "    print(\"cost: \"+str(cost))\n",
    "    fr.write(clas+\"-\"+ds+\" dataset:\\ncost= \"+str(cost)+\"\\nNumber of selected features:\"+str(len([i for i in pos if i==1]))+\"\\nSelected features:\"+str(pos))\n",
    "    return cost, pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train clssifier on the selected features (corrposining to pos which =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AUC(y_true,y_pred):\n",
    "    \n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    from sklearn.preprocessing import label_binarize\n",
    "    from sklearn.multiclass import OneVsRestClassifier\n",
    "    from scipy import interp\n",
    "\n",
    "    from sklearn.metrics import roc_curve  \n",
    "    from sklearn.metrics import roc_auc_score ,auc\n",
    "    from  sklearn.preprocessing import label_binarize \n",
    "    \n",
    "    classes=list(set(y))\n",
    "    y_test = label_binarize(y_true, classes=classes)\n",
    "    y_score = label_binarize(y_pred, classes=classes)\n",
    "\n",
    "    n_classes = len(classes)\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:,i], y_score[:,i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "    #auc = roc_auc_score(y,y_pred,average='micro')  \n",
    "      \n",
    "    \n",
    "\n",
    "    # Compute macro-average ROC curve and ROC area\n",
    "\n",
    "    # First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "    \n",
    "    \n",
    "    return roc_auc,tpr,fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(clas,X_train,X_test,y_train,y_test,pos, fr, fnum, filexs):   \n",
    "    \n",
    "    if(clas=='NB'):\n",
    "        classifier = GaussianNB()\n",
    "    elif(clas=='SVM linear'):\n",
    "        classifier = svm.SVC(kernel='linear')\n",
    "    elif(clas=='KNN'):\n",
    "        classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "    elif(clas=='SVM RBF'):\n",
    "        classifier = svm.SVC(kernel='rbf')\n",
    "        \n",
    "    # Get the selected features from the final positions\n",
    "    X_selected_features = X_train[:,pos==1]  # subset\n",
    "   \n",
    "    # Perform classification and store performance in P\n",
    "    classifier.fit(X_selected_features,y_train)\n",
    "    selected_test= X_test[:,pos==1]\n",
    "    \n",
    "    y_pred= classifier.predict(selected_test)    \n",
    "    report=classification_report(y_test,y_pred)\n",
    "    subset_performance = (y_pred== y_test).mean()\n",
    "    \n",
    "    print(len(list(set(y))))\n",
    "    if(len(list(set(y)))>2):\n",
    "        print('multi')\n",
    "        matrix = multilabel_confusion_matrix(y_test, y_pred)\n",
    "        tn = matrix[:, 0, 0]\n",
    "        tp = matrix[:, 1, 1]\n",
    "        fn = matrix[:, 1, 0]\n",
    "        fp = matrix[:, 0, 1]\n",
    "        G_mean= math.sqrt((tp.mean()/(tp.mean()+fn.mean()))*(tn.mean()/(fp.mean()+tn.mean())))\n",
    "    else:\n",
    "        print('binary')\n",
    "        matrix= confusion_matrix(y_test,y_pred, labels=list(set(y)))\n",
    "        tn, fp, fn, tp = matrix.ravel()\n",
    "        G_mean= math.sqrt((tp/(tp+fn))*(tn/(fp+tn)))\n",
    "    subset_performance = (y_pred== y_test).mean()\n",
    "    ac=accuracy_score(y_test,y_pred)\n",
    "    prec=precision_score(y_test,y_pred,average='weighted')\n",
    "    rc=recall_score(y_test,y_pred,average='weighted')\n",
    "    F_Score = (2 * rc * prec) / (rc + prec)  \n",
    "    auc=AUC(y_test,y_pred)[0][\"micro\"]\n",
    "    \n",
    "    fr.write(\"accuracy_score= {}\\n\".format(ac))\n",
    "    fr.write(\"precision_score= {}\\n\".format(prec))\n",
    "    fr.write(\"recall_score= {}\\n\".format(rc))\n",
    "    fr.write(\"F_Score= {}\\n\".format(F_Score))\n",
    "    fr.write(\"auc= {}\\n\".format(auc))\n",
    "    fr.write(\"G_mean= {}\\n\".format(G_mean))\n",
    "    \n",
    "    \n",
    "    \n",
    "    fr.write(\"confusion_matrix=\\n{}\\n\".format(matrix))\n",
    "    fr.write(\"labels {}\\n\".format(set(y)))\n",
    "    fr.write(\"True Negative= {}\\n\".format(tn))\n",
    "    fr.write(\"True Positive= {}\\n\".format(tp))\n",
    "    fr.write(\"Flase Negative= {}\\n\".format(fn))\n",
    "    fr.write(\"False Positive= {}\\n\".format(fp))\n",
    "\n",
    "    # Compute performance\n",
    "#     subset_performance = (classifier.predict(selected_test) == y_test).mean()\n",
    "    fr.write(\"\\nsubset_performance:\"+str(subset_performance)+\"\\n\")\n",
    "    fr.write(\"\\nclassification_report:\\n\"+str(report)+\"\\n\")\n",
    "    \n",
    "    print('Subset performance: %.3f' % (subset_performance))\n",
    "    \n",
    "    \n",
    "    filexs.loc[fnum] =[ds,prec,ac,rc,F_Score,auc,G_mean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The main cell "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here the classifier is created, options, number of iterations are set, and other methods are called"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "each results for each dataset are stored in results folder with file of the classifier name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, precision_score, recall_score, accuracy_score, f1_score\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder=\"D:\\\\SDP\\\\Dataset Dr.Sultan\\\\selected DS\"\n",
    "files = [os.path.join(root_folder, x) for x in os.listdir(root_folder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-08 19:35:06,706 - pyswarms.discrete.binary - INFO - Optimize for 100 iters with {'c1': 0.6, 'c2': 0.3, 'w': 0.4, 'k': 20, 'p': 2}\n",
      "pyswarms.discrete.binary: 100%|███████████████████████████████████████████████████████████████|100/100, best_cost=0.237\n",
      "2021-12-08 19:35:11,127 - pyswarms.discrete.binary - INFO - Optimization finished | best cost: 0.23728813559322035, best pos: [1 1 0 1 1 0 1 1 1 0 1 0 0 1 0 0 0 0 1 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost: 0.23728813559322035\n",
      "2\n",
      "binary\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-194d0c00c213>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.33\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[0mtrain_and_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclas\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfnum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilexs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[0mperiod\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mfr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'number of particle {}:\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-77901cc0fa49>\u001b[0m in \u001b[0;36mtrain_and_test\u001b[1;34m(clas, X_train, X_test, y_train, y_test, pos, fr, fnum, filexs)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mrc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mF_Score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mrc\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mprec\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrc\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mprec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mauc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAUC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"micro\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mfr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"accuracy_score= {}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mac\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-0b3359c7d11b>\u001b[0m in \u001b[0;36mAUC\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mroc_auc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mfpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mroc_auc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# classifier = GaussianNB()\n",
    "# clas='NB'\n",
    "\n",
    "# from sklearn import svm\n",
    "# classifier = svm.SVC(kernel='linear')\n",
    "# clas='SVM linear'\n",
    "\n",
    "# from sklearn import svm\n",
    "# classifier = svm.SVC(kernel='rbf')\n",
    "# clas='SVM RBF'\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "clas='KNN'\n",
    "\n",
    "# from sklearn import linear_model\n",
    "# classifier = linear_model.LogisticRegression(solver='lbfgs', multi_class='auto')\n",
    "# clas='Linear Regression'\n",
    "\n",
    "options = {'c1': 0.6, 'c2': 0.3, 'w': 0.4, 'k':20, 'p':2}\n",
    "# k : number of neighbors to be considered. Must be a positive integer less than n_partcles \n",
    "# p: the Minkowski p-norm to use. 1 is the sum-of-absolute values (or L1 distance) while 2 is the Euclidean (or L2) distance\n",
    "iters= 100\n",
    "\n",
    "\n",
    "\n",
    "fnum=-1\n",
    "filexs=pd.DataFrame(columns=[\"Dataset\", \"precision\", \"Accuracy\",\"Recall\",\"F-measure\",\"AUC\",\"G-mean\"])\n",
    "\n",
    "for file in files [0:1]:\n",
    "    fnum+=1\n",
    "    start= time.time()\n",
    "    \n",
    "    ds=file.split(\"\\\\\")[4][0:-4]\n",
    "    fr = open(\"C:/Users/Afnan/SDP/SDP/Test/BPSO/\"+clas+\"/{}.txt\".format(ds), \"a\")\n",
    "    fr.write('parameters: '+str(options)+\"\\n\")\n",
    "    \n",
    "    X,y = data_prepration(file)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    cost, pos = select_features(20)\n",
    "    train_and_test(clas,X_train,X_test,y_train,y_test,pos,fr, fnum,filexs)\n",
    "    period= time.time() - start \n",
    "    fr.write('number of particle {}:\\n'.format(20))\n",
    "    fr.write(\"best pos cost= \"+str(cost)+\"\\nNumber of selected features:\"+str(len([i for i in pos if i==1]))+\"\\nSelected features:\"+str(pos))\n",
    "    \n",
    "    fr.write('\\nFS, training, and testing time= '+str(period)+\" seconds\\n\")\n",
    "    fr.close()\n",
    "filexs.to_excel(\"BPSO {}.xlsx\".format(clas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
