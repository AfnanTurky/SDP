{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Import backend modules\n",
    "import pyswarms.backend as P\n",
    "from pyswarms.backend.topology import Star\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import arff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prepration(file):\n",
    "    data = arff.loadarff(file)\n",
    "    X=[]\n",
    "    y=[]\n",
    "    for i in data[0]:\n",
    "\n",
    "        X.append(list(i)[0:len(i)-2])\n",
    "        if(i[len(i)-1] == b'Y'):\n",
    "            y.append(1)\n",
    "        else:\n",
    "            y.append(0)\n",
    "        \n",
    "    X=np.array(X)\n",
    "    y=np.array(y)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_per_particle(m):\n",
    "    classifier = GaussianNB()\n",
    "    \"\"\"Computes for the fitness function per particle\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    m : numpy.ndarray\n",
    "        Binary mask that can be obtained from BinaryPSO, will\n",
    "        be used to mask features.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Computed finess function\n",
    "    \"\"\"\n",
    "    count_non_zero=np.count_nonzero(m)\n",
    "    # Get the subset of the features from the binary mask\n",
    "    if np.count_nonzero(m) == 0:\n",
    "        X_subset = X_train\n",
    "        X_subset_test= X_test\n",
    "        count_non_zero=len(m)\n",
    "    else:\n",
    "        \n",
    "        X_subset = X_train[:,m==1]\n",
    "        X_subset_test= X_test[:,m==1]\n",
    "        \n",
    "    \n",
    "    # Perform classification and compute the fitness function\n",
    "    classifier.fit(X_subset, y_train)\n",
    "    error_rate=(classifier.predict(X_subset_test) != y_test).mean()\n",
    "\n",
    "    j =  error_rate\n",
    "#     j=np.count_nonzero(m)\n",
    "\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    \"\"\"Higher-level method to do classification in the\n",
    "    whole swarm.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    x: numpy.ndarray of shape (n_particles, dimensions)\n",
    "        The swarm that will perform the search\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray of shape (n_particles, )\n",
    "        The computed loss for each particle\n",
    "    \"\"\"\n",
    "    n_particles = x.shape[0]\n",
    "    j = [f_per_particle(x[i]) for i in range(n_particles)]\n",
    "    \n",
    "    return np.array(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_position(swarm):\n",
    "        \"\"\"Update the position matrix of the swarm\n",
    "        This computes the next position in a binary swarm. It compares the\n",
    "        sigmoid output of the velocity-matrix and compares it with a randomly\n",
    "        generated matrix.\n",
    "        Parameters\n",
    "        ----------\n",
    "        swarm: pyswarms.backend.swarms.Swarm\n",
    "            a Swarm class\n",
    "        \"\"\"\n",
    "        \n",
    "        temp=np.random.random_sample(size=(swarm.n_particles,swarm.dimensions)) < swarm.velocity\n",
    "        postion=np.empty((my_swarm.n_particles, my_swarm.dimensions))\n",
    "        postion1=swarm.position\n",
    "\n",
    "        for j in range(swarm.n_particles):\n",
    "            for i in range(len(temp[0])):\n",
    "                if (temp[j][i] == True ):                  \n",
    "                    postion[j][i]=1-postion1[j][i]\n",
    "                else:\n",
    "                    postion[j][i]=postion1[j][i]\n",
    "            \n",
    "                \n",
    "        \n",
    "        return postion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_velocity(my_swarm, stickness,Is ,bounds=None):\n",
    "    \"\"\"Update the velocity matrix\n",
    "    This method updates the velocity matrix using the best and current\n",
    "    positions of the swarm. The velocity matrix is computed using the\n",
    "    cognitive and social terms of the swarm. The velocity is handled\n",
    "    by a :code:`VelocityHandler`.\n",
    "    A sample usage can be seen with the following:\n",
    "    .. code-block :: python\n",
    "        import pyswarms.backend as P\n",
    "        from pyswarms.swarms.backend import Swarm, VelocityHandler\n",
    "        my_swarm = P.create_swarm(n_particles, dimensions)\n",
    "        my_vh = VelocityHandler(strategy=\"invert\")\n",
    "        for i in range(iters):\n",
    "            # Inside the for-loop\n",
    "            my_swarm.velocity = compute_velocity(my_swarm, clamp, my_vh, bounds)\n",
    "    Parameters\n",
    "    ----------\n",
    "    swarm : pyswarms.backend.swarms.Swarm\n",
    "        a Swarm instance\n",
    "    clamp : tuple of floats, optional\n",
    "        a tuple of size 2 where the first entry is the minimum velocity\n",
    "        and the second entry is the maximum velocity. It\n",
    "        sets the limits for velocity clamping.\n",
    "    vh : pyswarms.backend.handlers.VelocityHandler\n",
    "        a VelocityHandler object with a specified handling strategy.\n",
    "        For further information see :mod:`pyswarms.backend.handlers`.\n",
    "    bounds : tuple of numpy.ndarray or list, optional\n",
    "        a tuple of size 2 where the first entry is the minimum bound while\n",
    "        the second entry is the maximum bound. Each array must be of shape\n",
    "        :code:`(dimensions,)`.\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Updated velocity matrix\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Prepare parameters\n",
    "        swarm_size = my_swarm.position.shape\n",
    "        alpha = my_swarm.options[\"c1\"]\n",
    "        gb=my_swarm.best_pos\n",
    "        Pb= my_swarm.pbest_pos\n",
    "        updated_velocity= np.empty((my_swarm.n_particles, my_swarm.dimensions))\n",
    "\n",
    "        for p in range(my_swarm.n_particles):\n",
    "            p_postion=my_swarm.position[p]\n",
    "            pb=Pb[p]\n",
    "\n",
    "            for i in range(len(p_postion)):                \n",
    "                if (p_postion[i] == pb[i] and   pb[i] == gb[i]):\n",
    "                    \n",
    "                    updated_velocity[p][i]=Is*(1-stickness[p][i])\n",
    "                elif(p_postion[i] == pb[i] and pb[i] != gb[i]):\n",
    "                    \n",
    "                    updated_velocity[p][i]=Is*(1-stickness[p][i] - (1/(alpha+1))) +(1/(alpha+1))\n",
    "                elif(p_postion[i] != pb[i] and p_postion[i]== gb[i]):\n",
    "                    \n",
    "                    updated_velocity[p][i]=Is*(1-stickness[p][i] - (alpha/(alpha+1))) +(alpha/(alpha+1))\n",
    "                elif(p_postion[i] != pb[i] and pb[i]== gb[i]):\n",
    "                    \n",
    "                    updated_velocity[p][i]= 1-Is*stickness[p][i]\n",
    "        \n",
    "\n",
    "    except AttributeError:\n",
    "        rep.logger.exception(\n",
    "            \"Please pass a Swarm class. You passed {}\".format(type(swarm))\n",
    "        )\n",
    "        raise\n",
    "    except KeyError:\n",
    "        rep.logger.exception(\"Missing keyword in swarm.options\")\n",
    "        raise\n",
    "    else:\n",
    "\n",
    "        return updated_velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stickness(stickness, old_position, ustkS, notchanged):\n",
    "    \n",
    "    new_stickness=np.empty((my_swarm.n_particles, my_swarm.dimensions))\n",
    "    new_position=my_swarm.position\n",
    "    \n",
    "    for j in range(my_swarm.n_particles):\n",
    "\n",
    "        \n",
    "        for i in range(len(stickness[j])):\n",
    "            if(new_position[j][i] == old_position[j][i]):\n",
    "                notchanged[j][i]+=1\n",
    "                if(notchanged[j][i] < ustkS):\n",
    "                    val=stickness[j][i] - (1/ustkS)\n",
    "                    if(val > 0):\n",
    "                        new_stickness[j][i]=val\n",
    "                    else:\n",
    "                        new_stickness[j][i]=0\n",
    "                else:\n",
    "                    new_stickness[j][i]=0   \n",
    "            else:\n",
    "                notchanged[j][i]=0\n",
    "                new_stickness[j][i]=1\n",
    "\n",
    "    return new_stickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AUC(y_true,y_pred):\n",
    "    \n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    from sklearn.preprocessing import label_binarize\n",
    "    from sklearn.multiclass import OneVsRestClassifier\n",
    "    from scipy import interp\n",
    "\n",
    "    from sklearn.metrics import roc_curve  \n",
    "    from sklearn.metrics import roc_auc_score ,auc\n",
    "    from  sklearn.preprocessing import label_binarize \n",
    "    \n",
    "    classes=list(set(y))\n",
    "    y_test = label_binarize(y_true, classes=classes)\n",
    "    y_score = label_binarize(y_pred, classes=classes)\n",
    "\n",
    "    n_classes = len(classes)\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:,i], y_score[:,i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "    #auc = roc_auc_score(y,y_pred,average='micro')  \n",
    "      \n",
    "    \n",
    "\n",
    "    # Compute macro-average ROC curve and ROC area\n",
    "\n",
    "    # First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "    \n",
    "    \n",
    "    return roc_auc,tpr,fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_swarm():\n",
    "   \n",
    "\n",
    "    stickness=np.random.random_sample(size=(my_swarm.n_particles,my_swarm.dimensions))\n",
    "    notchanged=np.zeros((my_swarm.n_particles,my_swarm.dimensions))\n",
    "\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        my_swarm.current_cost = f(my_swarm.position) # Compute current cost\n",
    "        my_swarm.pbest_cost = f(my_swarm.pbest_pos)  # Compute personal best pos\n",
    "        my_swarm.pbest_pos, my_swarm.pbest_cost = P.compute_pbest(my_swarm) # Update and store\n",
    "\n",
    "\n",
    "\n",
    "        Is=Isu-(i/iterations) *(Isu-Isl)\n",
    "        ustkS = ustkSL + (i/iterations) *(ustkSU- ustkSL)\n",
    "\n",
    "        # Part 2: Update global best\n",
    "        # Note that gbest computation is dependent on your topology\n",
    "        if np.min(my_swarm.pbest_cost) < my_swarm.best_cost:\n",
    "            my_swarm.best_pos, my_swarm.best_cost = my_topology.compute_gbest(my_swarm)\n",
    "        if i%20==0:\n",
    "                print('Iteration: {} | my_swarm.best_cost: {:.4f}'.format(i+1, my_swarm.best_cost))\n",
    "\n",
    "        my_swarm.velocity = compute_velocity(my_swarm, stickness, Is)\n",
    "        old_position= my_swarm.position\n",
    "        my_swarm.position = _compute_position(my_swarm)\n",
    "        stickness= compute_stickness(stickness,old_position, ustkS, notchanged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_folder=\"D:\\\\SDP\\\\Afnan\"\n",
    "files = [os.path.join(root_folder, x) for x in os.listdir(root_folder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, multilabel_confusion_matrix, precision_score, recall_score, accuracy_score, f1_score\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM1 dataset...\n",
      "Iteration: 1 | my_swarm.best_cost: 0.2222\n",
      "Iteration: 21 | my_swarm.best_cost: 0.2130\n",
      "Iteration: 41 | my_swarm.best_cost: 0.2037\n",
      "Iteration: 61 | my_swarm.best_cost: 0.1944\n",
      "Iteration: 81 | my_swarm.best_cost: 0.1944\n",
      "2\n",
      "binary\n",
      "subset performance= 0.8148148148148148\n",
      "JM1 dataset...\n",
      "Iteration: 1 | my_swarm.best_cost: 0.2067\n",
      "Iteration: 21 | my_swarm.best_cost: 0.2044\n",
      "Iteration: 41 | my_swarm.best_cost: 0.2036\n",
      "Iteration: 61 | my_swarm.best_cost: 0.2009\n",
      "Iteration: 81 | my_swarm.best_cost: 0.2001\n",
      "2\n",
      "binary\n",
      "subset performance= 0.8007006617360841\n",
      "KC1 dataset...\n",
      "Iteration: 1 | my_swarm.best_cost: 0.2609\n",
      "Iteration: 21 | my_swarm.best_cost: 0.2430\n",
      "Iteration: 41 | my_swarm.best_cost: 0.2430\n",
      "Iteration: 61 | my_swarm.best_cost: 0.2430\n",
      "Iteration: 81 | my_swarm.best_cost: 0.2430\n",
      "2\n",
      "binary\n",
      "subset performance= 0.7570332480818415\n",
      "KC3 dataset...\n",
      "Iteration: 1 | my_swarm.best_cost: 0.2154\n",
      "Iteration: 21 | my_swarm.best_cost: 0.2154\n",
      "Iteration: 41 | my_swarm.best_cost: 0.2154\n",
      "Iteration: 61 | my_swarm.best_cost: 0.2154\n",
      "Iteration: 81 | my_swarm.best_cost: 0.2154\n",
      "2\n",
      "binary\n",
      "subset performance= 0.7846153846153846\n",
      "MC1 dataset...\n",
      "Iteration: 1 | my_swarm.best_cost: 0.0381\n",
      "Iteration: 21 | my_swarm.best_cost: 0.0259\n",
      "Iteration: 41 | my_swarm.best_cost: 0.0244\n",
      "Iteration: 61 | my_swarm.best_cost: 0.0244\n",
      "Iteration: 81 | my_swarm.best_cost: 0.0244\n",
      "2\n",
      "binary\n",
      "subset performance= 0.9756468797564688\n",
      "MW1 dataset...\n",
      "Iteration: 1 | my_swarm.best_cost: 0.1905\n",
      "Iteration: 21 | my_swarm.best_cost: 0.1667\n",
      "Iteration: 41 | my_swarm.best_cost: 0.1667\n",
      "Iteration: 61 | my_swarm.best_cost: 0.1667\n",
      "Iteration: 81 | my_swarm.best_cost: 0.1548\n",
      "2\n",
      "binary\n",
      "subset performance= 0.8452380952380952\n",
      "PC1 dataset...\n",
      "Iteration: 1 | my_swarm.best_cost: 0.0944\n",
      "Iteration: 21 | my_swarm.best_cost: 0.0901\n",
      "Iteration: 41 | my_swarm.best_cost: 0.0858\n",
      "Iteration: 61 | my_swarm.best_cost: 0.0858\n",
      "Iteration: 81 | my_swarm.best_cost: 0.0858\n",
      "2\n",
      "binary\n",
      "subset performance= 0.9141630901287554\n",
      "PC2 dataset...\n",
      "Iteration: 1 | my_swarm.best_cost: 0.2764\n",
      "Iteration: 21 | my_swarm.best_cost: 0.0366\n",
      "Iteration: 41 | my_swarm.best_cost: 0.0366\n",
      "Iteration: 61 | my_swarm.best_cost: 0.0366\n",
      "Iteration: 81 | my_swarm.best_cost: 0.0325\n",
      "2\n",
      "binary\n",
      "subset performance= 0.967479674796748\n",
      "PC3 dataset...\n",
      "Iteration: 1 | my_swarm.best_cost: 0.2360\n",
      "Iteration: 21 | my_swarm.best_cost: 0.1629\n",
      "Iteration: 41 | my_swarm.best_cost: 0.1629\n",
      "Iteration: 61 | my_swarm.best_cost: 0.1629\n",
      "Iteration: 81 | my_swarm.best_cost: 0.1517\n",
      "2\n",
      "binary\n",
      "subset performance= 0.8651685393258427\n",
      "PC4 dataset...\n",
      "Iteration: 1 | my_swarm.best_cost: 0.1176\n",
      "Iteration: 21 | my_swarm.best_cost: 0.1012\n",
      "Iteration: 41 | my_swarm.best_cost: 0.0941\n",
      "Iteration: 61 | my_swarm.best_cost: 0.0941\n",
      "Iteration: 81 | my_swarm.best_cost: 0.0918\n",
      "2\n",
      "binary\n",
      "subset performance= 0.908235294117647\n",
      "PC5 dataset...\n",
      "Iteration: 1 | my_swarm.best_cost: 0.2690\n",
      "Iteration: 21 | my_swarm.best_cost: 0.2619\n",
      "Iteration: 41 | my_swarm.best_cost: 0.2602\n",
      "Iteration: 61 | my_swarm.best_cost: 0.2602\n",
      "Iteration: 81 | my_swarm.best_cost: 0.2584\n",
      "2\n",
      "binary\n",
      "subset performance= 0.7415929203539823\n"
     ]
    }
   ],
   "source": [
    "my_topology = Star() # The Topology Class\n",
    "my_options = {'c1': 0.6} # arbitrarily set\n",
    "n_particles= 20\n",
    "\n",
    "filexs=pd.DataFrame(columns=[\"Dataset\", \"precision\", \"Accuracy\",\"Recall\",\"F-measure\",\"AUC\",\"G-mean\"])\n",
    "fnum=-1\n",
    "for file in files:\n",
    "    fnum+=1\n",
    "    \n",
    "    ds=file.split(\"\\\\\")[3][0:-5]\n",
    "\n",
    "    print(\"{} dataset...\".format(ds))\n",
    "    \n",
    "#     ds=file\n",
    "    fr = open(\"C:/Users/afnan/SDP/SDP/Test Result/SBPSO DS2/NB/{}.txt\".format(ds), \"a\")\n",
    "    fr.write('parameters: '+str(my_options)+\"\\n\")\n",
    "    \n",
    "    # read the dataset and prepare it X for features and y for lables:\n",
    "    \n",
    "    X,y=data_prepration(file)\n",
    "    \n",
    "    # split dataset for training and testing DS\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    \n",
    "    # create swarm based on num of features and num of particles and the options \n",
    "    my_swarm = P.create_swarm(n_particles=n_particles,\n",
    "                              dimensions=X.shape[1], options=my_options, discrete=True, binary=True) # The Swarm Class\n",
    "    \n",
    "    # set swarm parameters \n",
    "    \n",
    "    iterations=100\n",
    "    ustkSL= 1*(iterations/100)\n",
    "    ustkSU= 8*(iterations/100)\n",
    "    Isu=0\n",
    "    Isl=10/my_swarm.dimensions\n",
    "    \n",
    "    # run swarm \n",
    "    run_swarm()\n",
    "    \n",
    "    # if the best pos no features select all features \n",
    "    if( np.count_nonzero( my_swarm.best_pos) == 0):\n",
    "        my_swarm.best_pos= np.ones(my_swarm.dimensions)\n",
    "    \n",
    "    # train the classfier on the selected features \n",
    "    classifier =GaussianNB()\n",
    "    X_selected_features = X_train[:,my_swarm.best_pos==1]\n",
    "    X_selected_features_test= X_test[:,my_swarm.best_pos==1]\n",
    "    classifier.fit(X_selected_features, y_train)\n",
    "    \n",
    "    # test it and evaluate \n",
    "    y_pred= classifier.predict(X_selected_features_test)    \n",
    "    report=classification_report(y_test,y_pred)\n",
    "    subset_performance = (y_pred== y_test).mean()\n",
    "    \n",
    "    print(len(list(set(y))))\n",
    "    if(len(list(set(y)))>2):\n",
    "        print('multi')\n",
    "        matrix = multilabel_confusion_matrix(y_test, y_pred)\n",
    "        tn = matrix[:, 0, 0]\n",
    "        tp = matrix[:, 1, 1]\n",
    "        fn = matrix[:, 1, 0]\n",
    "        fp = matrix[:, 0, 1]\n",
    "        G_mean= math.sqrt((tp.mean()/(tp.mean()+fn.mean()))*(tn.mean()/(fp.mean()+tn.mean())))\n",
    "        auc=AUC(y_test,y_pred)[0][\"micro\"]\n",
    "    else:\n",
    "        print('binary')\n",
    "        matrix= confusion_matrix(y_test,y_pred, labels=list(set(y)))\n",
    "        tn, fp, fn, tp = matrix.ravel()\n",
    "        G_mean= math.sqrt((tp/(tp+fn))*(tn/(fp+tn)))\n",
    "        auc=roc_auc_score(y_test,y_pred)\n",
    "        \n",
    "    ac=accuracy_score(y_test,y_pred)\n",
    "    prec=precision_score(y_test,y_pred,average='weighted')\n",
    "    rc=recall_score(y_test,y_pred,average='weighted')\n",
    "    F_Score = (2 * rc * prec) / (rc + prec)  \n",
    "    \n",
    "    \n",
    "    # store the result \n",
    "    print(\"subset performance= {}\".format(subset_performance))\n",
    "    fr.write('number of particle {}:\\n'.format(n_particles))\n",
    "    fr.write(\"best pos cost= \"+str(my_swarm.best_cost)+\"\\nNumber of selected features:\"+str(len([i for i in my_swarm.best_pos if i==1]))+\"\\nSelected features:\"+str(my_swarm.best_pos))\n",
    "    fr.write(\"\\nclassification_report:\"+str(report)+\"\\n\")\n",
    "    fr.write(\"subset performance = {}\".format(subset_performance))\n",
    "    \n",
    "    fr.write(\"accuracy_score= {}\\n\".format(ac))\n",
    "    fr.write(\"precision_score= {}\\n\".format(prec))\n",
    "    fr.write(\"recall_score= {}\\n\".format(rc))\n",
    "    fr.write(\"F_Score= {}\\n\".format(F_Score))\n",
    "    fr.write(\"auc= {}\\n\".format(auc))\n",
    "    fr.write(\"G_mean= {}\\n\".format(G_mean))\n",
    "    \n",
    "    \n",
    "    \n",
    "    fr.write(\"confusion_matrix=\\n{}\\n\".format(matrix))\n",
    "    fr.write(\"labels {}\\n\".format(set(y)))\n",
    "    fr.write(\"True Negative= {}\\n\".format(tn))\n",
    "    fr.write(\"True Positive= {}\\n\".format(tp))\n",
    "    fr.write(\"Flase Negative= {}\\n\".format(fn))\n",
    "    fr.write(\"False Positive= {}\\n\".format(fp))\n",
    "    fr.close()\n",
    "    #[\"Dataset\", \"precision\", \"Accuracy\",\"Recall\",\"F-measure\",\"AUC\",\"G-mean\"]\n",
    "\n",
    "    filexs.loc[fnum] =[ds,prec,ac,rc,F_Score,auc,G_mean]\n",
    "filexs.to_excel(\"SBPSO NB DS2.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
