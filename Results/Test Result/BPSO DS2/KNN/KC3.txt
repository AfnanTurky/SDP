parameters: {'c1': 0.6, 'c2': 0.3, 'w': 0.4, 'k': 20, 'p': 2}
KNN-KC3 dataset:
cost= 0.2153846153846154
Number of selected features:16
Selected features:[1 1 1 1 0 1 0 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0
 1]
subset_performance:0.7846153846153846

classification_report:              precision    recall  f1-score   support

           0       0.80      0.96      0.88        51
           1       0.50      0.14      0.22        14

    accuracy                           0.78        65
   macro avg       0.65      0.55      0.55        65
weighted avg       0.74      0.78      0.73        65

accuracy_score= 0.7846153846153846
precision_score= 0.7379571248423707
recall_score= 0.7846153846153846
F_Score= 0.7605713484792497
auc= 0.5518207282913165
G_mean= 0.37047928681747416
confusion_matrix=
[[49  2]
 [12  2]]
labels {0, 1}
True Negative= 49
True Positive= 2
Flase Negative= 12
False Positive= 2
number of particle 20:
best pos cost= 0.2153846153846154
Number of selected features:16
Selected features:[1 1 1 1 0 1 0 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0
 1]
FS, training, and testing time= 5.933271884918213 seconds
