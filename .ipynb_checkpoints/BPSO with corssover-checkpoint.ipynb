{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Import backend modules\n",
    "import pyswarms.backend as P\n",
    "from pyswarms.backend.topology import Star\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_per_particle(m):\n",
    "    classifier = GaussianNB()\n",
    "    \"\"\"Computes for the fitness function per particle\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    m : numpy.ndarray\n",
    "        Binary mask that can be obtained from BinaryPSO, will\n",
    "        be used to mask features.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Computed finess function\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the subset of the features from the binary mask\n",
    "    if np.count_nonzero(m) == 0:\n",
    "        X_subset = X\n",
    "    else:\n",
    "        X_subset = X[:,m==1]\n",
    "   \n",
    "    # Perform classification and compute the fitness function\n",
    "    classifier.fit(X_subset, y)\n",
    "    j = (classifier.predict(X_subset) != y).mean() + np.count_nonzero(m)\n",
    "#     j=np.count_nonzero(m)\n",
    "\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    \"\"\"Higher-level method to do classification in the\n",
    "    whole swarm.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    x: numpy.ndarray of shape (n_particles, dimensions)\n",
    "        The swarm that will perform the search\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray of shape (n_particles, )\n",
    "        The computed loss for each particle\n",
    "    \"\"\"\n",
    "    n_particles = x.shape[0]\n",
    "    j = [f_per_particle(x[i]) for i in range(n_particles)]\n",
    "    \n",
    "    return np.array(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_position(swarm):\n",
    "        \"\"\"Update the position matrix of the swarm\n",
    "        This computes the next position in a binary swarm. It compares the\n",
    "        sigmoid output of the velocity-matrix and compares it with a randomly\n",
    "        generated matrix.\n",
    "        Parameters\n",
    "        ----------\n",
    "        swarm: pyswarms.backend.swarms.Swarm\n",
    "            a Swarm class\n",
    "        \"\"\"\n",
    "        return (\n",
    "            np.random.random_sample(size=swarm.dimensions)\n",
    "            < _sigmoid(swarm.velocity)\n",
    "        ) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sigmoid( x):\n",
    "        \"\"\"Helper method for the sigmoid function\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : numpy.ndarray\n",
    "            Input vector for sigmoid computation\n",
    "        Returns\n",
    "        -------\n",
    "        numpy.ndarray\n",
    "            Output sigmoid computation\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'child2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-e10406a17d03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mchild2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'child2' is not defined"
     ]
    }
   ],
   "source": [
    "child2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 | my_swarm.best_cost: 2.1812\n",
      "Iteration: 21 | my_swarm.best_cost: 2.1812\n",
      "Iteration: 41 | my_swarm.best_cost: 2.1812\n",
      "Iteration: 61 | my_swarm.best_cost: 2.1812\n",
      "Iteration: 81 | my_swarm.best_cost: 2.1812\n"
     ]
    }
   ],
   "source": [
    "mid=my_swarm.dimensions//2\n",
    "iterations=100\n",
    "for i in range(iterations):\n",
    "    my_swarm.current_cost = f(my_swarm.position) # Compute current cost\n",
    "    my_swarm.pbest_cost = f(my_swarm.pbest_pos)  # Compute personal best pos\n",
    "    my_swarm.pbest_pos, my_swarm.pbest_cost = P.compute_pbest(my_swarm) # Update and store\n",
    "    \n",
    "    \n",
    "    if(i!=0):\n",
    "        \n",
    "        for p in my_swarm.pbest_pos:\n",
    "            # cross-over between Pbest and Gbest \n",
    "            child1= np.concatenate((p[0:mid] , my_swarm.best_pos[mid:]) ,axis=0) \n",
    "            child2 =np.concatenate((my_swarm.best_pos[0:mid] , p[mid:]) ,axis=0)\n",
    "\n",
    "            # for each child, compute fitness function\n",
    "            child1_cost=f_per_particle(child1)\n",
    "            child2_cost=f_per_particle(child2)\n",
    "\n",
    "             # update Gbest based on the best child \n",
    "            if(child1_cost < child2_cost and child1_cost<my_swarm.best_cost ):\n",
    "                my_swarm.best_cost =child1_cost\n",
    "                my_swarm.best_pos = child1\n",
    "            elif(child2_cost < child1_cost and child2_cost< my_swarm.best_cost ):\n",
    "                my_swarm.best_cost =child2_cost\n",
    "                my_swarm.best_pos = child2\n",
    "    else:\n",
    "        my_swarm.best_pos, my_swarm.best_cost = my_topology.compute_gbest(my_swarm)\n",
    "    if i%20==0:\n",
    "            print('Iteration: {} | my_swarm.best_cost: {:.4f}'.format(i+1, my_swarm.best_cost))\n",
    "\n",
    "    my_swarm.velocity = my_topology.compute_velocity(my_swarm)\n",
    "    my_swarm.position = _compute_position(my_swarm)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('D:\\\\SDP\\\\Dataset Dr.Sultan\\\\ant.csv')\n",
    "X=np.array(df.drop('bug', axis=1))\n",
    "y=np.array(df.bug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are the attributes of our swarm: dict_keys(['position', 'velocity', 'n_particles', 'dimensions', 'options', 'pbest_pos', 'best_pos', 'pbest_cost', 'best_cost', 'current_cost'])\n"
     ]
    }
   ],
   "source": [
    "my_topology = Star() # The Topology Class\n",
    "my_options = {'c1': 0.6, 'c2': 0.3, 'w': 0.4} # arbitrarily set\n",
    "my_swarm = P.create_swarm(n_particles=50, dimensions=X.shape[1], options=my_options, discrete=True, binary=True) # The Swarm Class\n",
    "\n",
    "print('The following are the attributes of our swarm: {}'.format(my_swarm.__dict__.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = GaussianNB()\n",
    "X_selected_features = X[:,my_swarm.best_pos==1]\n",
    "classifier.fit(X_selected_features, y)\n",
    "subset_performance = (classifier.predict(X_selected_features) == y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8187919463087249"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr = open(\"Results/with corssover/NB.txt\", \"a\")\n",
    "fr.write('NB\\nparameters: '+str(my_options)+\"\\n\")\n",
    "fr.write(\"NB-ant dataset:\\ncost= \"+str(my_swarm.best_cost)+\"\\nNumber of selected features:\"+str(len([i for i in my_swarm.best_pos if i==1]))+\"\\nSelected features:\"+str(my_swarm.best_pos))\n",
    "fr.write(\"\\nsubset_performance:\"+str(subset_performance)+\"\\n\")\n",
    "fr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
