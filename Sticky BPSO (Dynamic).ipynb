{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Import backend modules\n",
    "import pyswarms.backend as P\n",
    "from pyswarms.backend.topology import Star\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_per_particle(m):\n",
    "    classifier = GaussianNB()\n",
    "    \"\"\"Computes for the fitness function per particle\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    m : numpy.ndarray\n",
    "        Binary mask that can be obtained from BinaryPSO, will\n",
    "        be used to mask features.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Computed finess function\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the subset of the features from the binary mask\n",
    "    if np.count_nonzero(m) == 0:\n",
    "        X_subset = X_train\n",
    "        X_subset_test= X_test\n",
    "    else:\n",
    "        X_subset = X_train[:,m==1]\n",
    "        X_subset_test= X_test[:,m==1]\n",
    "        \n",
    "    \n",
    "    # Perform classification and compute the fitness function\n",
    "    classifier.fit(X_subset, y_train)\n",
    "    j = (classifier.predict(X_subset_test) != y_test).mean() + np.count_nonzero(m)\n",
    "#     j=np.count_nonzero(m)\n",
    "\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    \"\"\"Higher-level method to do classification in the\n",
    "    whole swarm.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    x: numpy.ndarray of shape (n_particles, dimensions)\n",
    "        The swarm that will perform the search\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray of shape (n_particles, )\n",
    "        The computed loss for each particle\n",
    "    \"\"\"\n",
    "    n_particles = x.shape[0]\n",
    "    j = [f_per_particle(x[i]) for i in range(n_particles)]\n",
    "    \n",
    "    return np.array(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_position(swarm):\n",
    "        \"\"\"Update the position matrix of the swarm\n",
    "        This computes the next position in a binary swarm. It compares the\n",
    "        sigmoid output of the velocity-matrix and compares it with a randomly\n",
    "        generated matrix.\n",
    "        Parameters\n",
    "        ----------\n",
    "        swarm: pyswarms.backend.swarms.Swarm\n",
    "            a Swarm class\n",
    "        \"\"\"\n",
    "        \n",
    "        temp=np.random.random_sample(size=(swarm.n_particles,swarm.dimensions)) < swarm.velocity\n",
    "        postion=np.empty((my_swarm.n_particles, my_swarm.dimensions))\n",
    "        postion1=swarm.position\n",
    "        \n",
    "        for j in range(swarm.n_particles):\n",
    "            for i in range(len(temp[0])):\n",
    "                if (temp[j][i] is True ):\n",
    "                    postion[j][i]=1-postion1[j][i]\n",
    "                else:\n",
    "                    postion[j][i]=postion1[j][i]\n",
    "                \n",
    "        \n",
    "        return postion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_velocity(my_swarm, stickness, bounds=None):\n",
    "    \"\"\"Update the velocity matrix\n",
    "    This method updates the velocity matrix using the best and current\n",
    "    positions of the swarm. The velocity matrix is computed using the\n",
    "    cognitive and social terms of the swarm. The velocity is handled\n",
    "    by a :code:`VelocityHandler`.\n",
    "    A sample usage can be seen with the following:\n",
    "    .. code-block :: python\n",
    "        import pyswarms.backend as P\n",
    "        from pyswarms.swarms.backend import Swarm, VelocityHandler\n",
    "        my_swarm = P.create_swarm(n_particles, dimensions)\n",
    "        my_vh = VelocityHandler(strategy=\"invert\")\n",
    "        for i in range(iters):\n",
    "            # Inside the for-loop\n",
    "            my_swarm.velocity = compute_velocity(my_swarm, clamp, my_vh, bounds)\n",
    "    Parameters\n",
    "    ----------\n",
    "    swarm : pyswarms.backend.swarms.Swarm\n",
    "        a Swarm instance\n",
    "    clamp : tuple of floats, optional\n",
    "        a tuple of size 2 where the first entry is the minimum velocity\n",
    "        and the second entry is the maximum velocity. It\n",
    "        sets the limits for velocity clamping.\n",
    "    vh : pyswarms.backend.handlers.VelocityHandler\n",
    "        a VelocityHandler object with a specified handling strategy.\n",
    "        For further information see :mod:`pyswarms.backend.handlers`.\n",
    "    bounds : tuple of numpy.ndarray or list, optional\n",
    "        a tuple of size 2 where the first entry is the minimum bound while\n",
    "        the second entry is the maximum bound. Each array must be of shape\n",
    "        :code:`(dimensions,)`.\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Updated velocity matrix\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Prepare parameters\n",
    "        swarm_size = my_swarm.position.shape\n",
    "        alpha = my_swarm.options[\"c1\"]\n",
    "        gb=my_swarm.best_pos\n",
    "        Pb= my_swarm.pbest_pos\n",
    "        updated_velocity= np.empty((my_swarm.n_particles, my_swarm.dimensions))\n",
    "        for p in range(my_swarm.n_particles):\n",
    "            p_postion=my_swarm.position[p]\n",
    "            pb=Pb[p]\n",
    "            \n",
    "            for i in range(len(p_postion)):\n",
    "                \n",
    "                \n",
    "                if (p_postion[i] == pb[i] == gb[i]):\n",
    "                    updated_velocity[p][i]=Is*(1-stickness[p][i])\n",
    "                elif(p_postion[i] == pb[i] != gb[i]):\n",
    "                    updated_velocity[p][i]=Is*(1-stickness[p][i] - (1/(alpha+1))) +(1/(alpha+1))\n",
    "                elif(p_postion[i] != pb[i] and p_postion[i]== gb[i]):\n",
    "                    updated_velocity[p][i]=Is*(1-stickness[p][i] - (alpha/(alpha+1))) +(alpha/(alpha+1))\n",
    "                elif(p_postion[i] != pb[i] and pb[i]== gb[i]):\n",
    "                    updated_velocity[p][i]= 1-Is*stickness[p][i]\n",
    "        \n",
    "\n",
    "    except AttributeError:\n",
    "        rep.logger.exception(\n",
    "            \"Please pass a Swarm class. You passed {}\".format(type(swarm))\n",
    "        )\n",
    "        raise\n",
    "    except KeyError:\n",
    "        rep.logger.exception(\"Missing keyword in swarm.options\")\n",
    "        raise\n",
    "    else:\n",
    "        return updated_velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stickness(stickness, old_position):\n",
    "    \n",
    "    new_stickness=np.empty((my_swarm.n_particles, my_swarm.dimensions))\n",
    "    new_position=my_swarm.position\n",
    "    \n",
    "    for j in range(my_swarm.n_particles):\n",
    "        \n",
    "        for i in range(len(stickness[j])):\n",
    "            if(new_position[j][i] == old_position[j][i]):\n",
    "                notchanged[j][i]+=1\n",
    "                if(notchanged[j][i] < ustkS):\n",
    "                    val=stickness[j][i] - (1/ustkS)\n",
    "                    if(val > 0):\n",
    "                        new_stickness[j][i]=val\n",
    "                    else:\n",
    "                        new_stickness[j][i]=0\n",
    "                else:\n",
    "                    new_stickness[j][i]=0   \n",
    "            else:\n",
    "                notchanged[j][i]=0\n",
    "                new_stickness[j][i]=1\n",
    "    return new_stickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df=pd.read_csv('D:\\\\SDP\\\\Dataset Dr.Sultan\\\\ant.csv')\n",
    "X=np.array(df.drop('bug', axis=1))\n",
    "y=np.array(df.bug)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are the attributes of our swarm: dict_keys(['position', 'velocity', 'n_particles', 'dimensions', 'options', 'pbest_pos', 'best_pos', 'pbest_cost', 'best_cost', 'current_cost'])\n"
     ]
    }
   ],
   "source": [
    "my_topology = Star() # The Topology Class\n",
    "my_options = {'c1': 0.6} # arbitrarily set\n",
    "my_swarm = P.create_swarm(n_particles=50,\n",
    "                          dimensions=X.shape[1], options=my_options, discrete=True, binary=True) # The Swarm Class\n",
    "\n",
    "print('The following are the attributes of our swarm: {}'.format(my_swarm.__dict__.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 | my_swarm.best_cost: 2.1911\n",
      "Iteration: 21 | my_swarm.best_cost: 2.1911\n",
      "Iteration: 41 | my_swarm.best_cost: 2.1911\n",
      "Iteration: 61 | my_swarm.best_cost: 2.1911\n",
      "Iteration: 81 | my_swarm.best_cost: 2.1911\n"
     ]
    }
   ],
   "source": [
    "iterations=100\n",
    "\n",
    "stickness=np.random.random_sample(size=(my_swarm.n_particles,my_swarm.dimensions))\n",
    "notchanged=np.zeros((my_swarm.n_particles,my_swarm.dimensions))\n",
    "\n",
    "\n",
    "ustkSL= 1*(iterations/100)\n",
    "ustkSU= 8*(iterations/100)\n",
    "Isu=0\n",
    "Isl=10/my_swarm.dimensions\n",
    "\n",
    "for i in range(iterations):\n",
    "    my_swarm.current_cost = f(my_swarm.position) # Compute current cost\n",
    "    my_swarm.pbest_cost = f(my_swarm.pbest_pos)  # Compute personal best pos\n",
    "    my_swarm.pbest_pos, my_swarm.pbest_cost = P.compute_pbest(my_swarm) # Update and store\n",
    "    \n",
    "    Is=Isu-(i/iterations) *(Isu-Isl)\n",
    "    ustkS = ustkSL + (i/iterations) *(ustkSU- ustkSL)\n",
    "         \n",
    "    # Part 2: Update global best\n",
    "    # Note that gbest computation is dependent on your topology\n",
    "    if np.min(my_swarm.pbest_cost) < my_swarm.best_cost:\n",
    "        my_swarm.best_pos, my_swarm.best_cost = my_topology.compute_gbest(my_swarm)\n",
    "    if i%20==0:\n",
    "            print('Iteration: {} | my_swarm.best_cost: {:.4f}'.format(i+1, my_swarm.best_cost))\n",
    "\n",
    "    my_swarm.velocity = compute_velocity(my_swarm, stickness)\n",
    "    old_position= my_swarm.position\n",
    "    my_swarm.position = _compute_position(my_swarm)\n",
    "    stickness= compute_stickness(stickness,old_position)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = GaussianNB()\n",
    "X_selected_features = X_train[:,my_swarm.best_pos==1]\n",
    "X_selected_features_test= X_test[:,my_swarm.best_pos==1]\n",
    "classifier.fit(X_selected_features, y_train)\n",
    "subset_performance = (classifier.predict(X_selected_features) == y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8187919463087249"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr = open(\"Results/with corssover/NB.txt\", \"a\")\n",
    "fr.write('NB\\nparameters: '+str(my_options)+\"\\n\")\n",
    "fr.write(\"NB-ant dataset:\\ncost= \"+str(my_swarm.best_cost)+\"\\nNumber of selected features:\"+str(len([i for i in my_swarm.best_pos if i==1]))+\"\\nSelected features:\"+str(my_swarm.best_pos))\n",
    "fr.write(\"\\nsubset_performance:\"+str(subset_performance)+\"\\n\")\n",
    "fr.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
